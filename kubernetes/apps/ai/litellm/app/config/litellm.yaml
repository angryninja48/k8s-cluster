model_list:
# -*= Paid models =*-
# -------------------

  # Anthropic models
  - model_name: "claude-3.5-sonnet-20240620"
    litellm_params:
      model: "claude-3-5-sonnet-20240620"
      tags: ["paid"]
      api_key: {{ .LITELLM_ANTHROPIC_API_KEY }}

  # Bedrock models

  - model_name: bedrock-claude-3.7
    litellm_params:
      model: bedrock/anthropic.claude-3-7-sonnet-20250219-v1:0
      model_id: arn:aws:bedrock:{{ .LITELLM_BEDROCK_REGION }}:{{ .LITELLM_BEDROCK_ACCOUNT }}:inference-profile/us.anthropic.claude-3-7-sonnet-20250219-v1:0
      aws_access_key_id: {{ .LITELLM_BEDROCK_ACCESS_KEY }}
      aws_secret_access_key: {{ .LITELLM_BEDROCK_SECRET_KEY }}
      aws_region_name: {{ .LITELLM_BEDROCK_REGION }}

  # Openrouter

  - model_name: gemini-3-pro-preview
    litellm_params:
      model: openrouter/google/gemini-3-pro-preview
      api_key: {{ .LITELLM_OPENROUTER_API_KEY }}

# -*= Free models =*-
# -------------------
  - model_name: gpt-4o-mini
    litellm_params:
      model: openai/gpt-4o-mini
      api_key: {{ .LITELLM_OPENAI_API_KEY }}
      tags: ["free"]

  - model_name: qwen2.5-coder-32b-instruct-free
    litellm_params:
      model: openrouter/qwen/qwen-2.5-coder-32b-instruct:free
      api_key: {{ .LITELLM_OPENROUTER_API_KEY }}

# -*= Self Hosted models =*-
# -------------------

  - model_name: llama3.2
    litellm_params:
      model: ollama/llama3.2
      api_base: "http://10.20.0.7:11434"

  - model_name: "mxbai-embed-large"
    litellm_params:
      model: "ollama/mxbai-embed-large:latest"
      api_base: "http://10.20.0.7:11434"

  - model_name: "deepseek-r1:1.5b"
    litellm_params:
      model: "ollama_chat/deepseek-r1:1.5b"
      api_base: "http://10.20.0.7:11434"

  - model_name: "codellama-7b"
    litellm_params:
      model: "ollama_chat/codellama:7b"
      api_base: "http://10.20.0.7:11434"


embeddings:
  ollama:
    model_name: "mxbai-embed-large"
    version: "latest"  # Ensure the version is specified if needed
    api_url: "http://10.20.0.7:11434"

router_settings:
  routing_strategy: simple-shuffle
  num_retries: 3

general_settings:
  master_key: {{ .LITELLM_MASTER_KEY }}
  database_url: "postgresql://{{ .LITELLM_POSTGRES_USER }}:{{ .LITELLM_POSTGRES_PASSWORD }}@postgres17-rw.database.svc.cluster.local/litellm"
  # enforce_user_param: true

litellm_settings:
  num_retries: 3
  request_timeout: 180
  allowed_fails: 3
  cooldown_time: 30
  drop_params: true
  modify_params: true
  telemetry: false
  retry: true
  add_function_to_prompt: true

  set_verbose: false
  cache: true
  cache_params:        # set cache params for redis
    type: redis
    namespace: "litellm_caching"
    host: dragonfly.database.svc.cluster.local.
    port: 6379
